---
id: graph-embedding
title: Graph Embedding
sidebar_position: 2
---

# Graph Embedding
그래프 임베딩(Graph Embedding)은 그래프 구조를 저차원 벡터 공간에 표현하는 방법
그래프의 노드, 엣지, 서브그래프 등을 벡터로 변환하여 머신러닝 알고리즘에 활용할 수 있도록 함
그래프 임베딩의 주요 목표는 그래프의 구조적 특성과 속성 정보를 보존하면서, 그래프 데이터를 효율적으로 표현하는 것

ML workflow에서는 임베딩이 별도의 단계로 생성되어 회귀나 분류와 같은 작업에서 차원 축소 기법으로 사용 [!추후링크]
그러나, GNN은 임베딩 생성을 모델의 학습 과정과 통합한다. 왜? 앞서 봤던, 계층[!Graph Basic.mdx 마지막 부분 링크]을 통해 입력을
처리함에 따라 임베딩이 정제되고 업데이트되므로 학습 단계와 임베딩 단게가 분리 될 수 없음!
-> 내가 이해한대로 다시 기술

## Node2Vec
비GNN접근 방식 -> 실제 적용 과정
정치 서적 구매 그래프에 대한 사례 연구 [!참고링크]

https://github.com/keitabroadwater/gnns_in_action/tree/master/chapter_2

뭔가 이름이 익숙하지 않은가? NLP영역에서 Word2Vec [!추후링크]에서 영감을 받았다고 한다.
N2V는 random walks(이게 뭔지 다시 용어 찾아)를 시뮬레이션하여 그래프 내 노드의 맥락을 포착 -> 저차원 공가에서 노드 간의 인접 관게를 파악할 수 있도록 함
